{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test using Newick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"(A,B,(C,D)E)F\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ┌─A\n",
      "──F─┼─B\n",
      "    │   ┌─C\n",
      "    └─E─┤\n",
      "        └─D\n"
     ]
    }
   ],
   "source": [
    "from newick import loads\n",
    "\n",
    "trees = loads('(A,B,(C,D)E)F;')\n",
    "\n",
    "print(trees[0].ascii_art())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', 'B', 'E']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[n.name for n in trees[0].descendants]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ┌─G\n",
      "    ┌─A─┤\n",
      "    │   │   ┌─Y\n",
      "    │   └───┤\n",
      "──F─┤       └─Z\n",
      "    │   ┌─C\n",
      "    └─E─┤\n",
      "        └─D\n",
      "{'G', 'C', 'Y', 'A', 'D', 'E', 'Z'}\n",
      "Split 1: ({'A', 'G', 'Z', 'Y'}, {'D', 'E', 'C'})\n",
      "Split 2: ({'Z', 'Y'}, {'G', 'C', 'A', 'D', 'E'})\n",
      "Split 3: ({'D', 'E', 'C'}, {'A', 'G', 'Z', 'Y'})\n"
     ]
    }
   ],
   "source": [
    "from newick import loads\n",
    "\n",
    "# Load the tree from the Newick string\n",
    "trees = loads('((G,B(Y,Z))A,(C,D)E)F;')\n",
    "tree = trees[0]  # Since we have only one tree in the list\n",
    "\n",
    "print(trees[0].ascii_art())\n",
    "\n",
    "\n",
    "# Function to get the leaf names under a node\n",
    "def get_leaves(node):\n",
    "    if node.is_leaf:\n",
    "        return {node.name}\n",
    "    leaves = set()\n",
    "    if node.name:\n",
    "        leaves = {node.name}\n",
    "    for child in node.descendants:\n",
    "        leaves.update(get_leaves(child))\n",
    "    return leaves\n",
    "\n",
    "# Function to compute all splits from the tree\n",
    "def get_splits(node, all_leaves):\n",
    "    splits = []\n",
    "    if not node.is_leaf:\n",
    "        # Get the leaves under this node\n",
    "        subtree_leaves = get_leaves(node)\n",
    "\n",
    "        # Remaining leaves are those not in the subtree\n",
    "        remaining_leaves = all_leaves - subtree_leaves\n",
    "\n",
    "        # Add the split (subtree_leaves, remaining_leaves)\n",
    "        if remaining_leaves and subtree_leaves:\n",
    "            splits.append((subtree_leaves, remaining_leaves))\n",
    "\n",
    "\n",
    "        # Recursively compute splits for each child\n",
    "        for child in node.descendants:\n",
    "            splits.extend(get_splits(child, all_leaves))\n",
    "            #splits.extend(get_splits(child, subtree_leaves))\n",
    "            \n",
    "        if node.is_leaf:\n",
    "            single_leaf_split = ({node.name}, subtree_leaves - {node.name})\n",
    "            splits.append(single_leaf_split)\n",
    "\n",
    "    return splits\n",
    "\n",
    "def return_splits(tree):\n",
    "    # Get all leaves of the tree except the first one\n",
    "    all_leaves = get_leaves(tree) - {tree.name}\n",
    "    print(all_leaves)\n",
    "    # Compute all the splits\n",
    "    return get_splits(tree, all_leaves)\n",
    "\n",
    "# Compute all the splits\n",
    "splits = return_splits(tree)\n",
    "\n",
    "# Output the splits\n",
    "for i, split in enumerate(splits, 1):\n",
    "    print(f\"Split {i}: {split}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1: ({'U'}, {'V'})\n",
      "Split 2: ({'Y'}, {'V', 'U'})\n",
      "Split 3: ({'G'}, {'V', 'U', 'Y'})\n",
      "Split 4: ({'C'}, {'D'})\n",
      "Split 5: ({'G', 'V', 'Y', 'A', 'U'}, {'D', 'E', 'C'})\n"
     ]
    }
   ],
   "source": [
    "from newick import loads\n",
    "\n",
    "# Load the tree from the Newick string\n",
    "trees = loads('((G,B(Y,Z(U,V)))A,(C,D)E)F;')\n",
    "tree = trees[0]  # Since we have only one tree in the list\n",
    "\n",
    "\n",
    "# Function to get the node names under a node\n",
    "def get_nodes(node):\n",
    "    if node.is_leaf:\n",
    "        return {node.name}\n",
    "\n",
    "    leaves = set()\n",
    "\n",
    "    for child in node.descendants:\n",
    "        leaves.update(get_nodes(child))\n",
    "    if node.name:\n",
    "        leaves.add(node.name)\n",
    "    return leaves\n",
    "\n",
    "\n",
    "# Function to compute splits for RF distance (excluding trivial splits)\n",
    "def get_splits(node):\n",
    "    splits = []\n",
    "\n",
    "    if node.is_leaf:\n",
    "        return splits\n",
    "\n",
    "    current_leaves = []\n",
    "    for descendant in node.descendants:\n",
    "        current_leaves.append(get_nodes(descendant))\n",
    "        splits += get_splits(descendant)\n",
    "    splits.append(tuple(current_leaves))\n",
    "\n",
    "    return splits\n",
    "\n",
    "\n",
    "# Compute all the splits for RF\n",
    "splits = get_splits(tree)\n",
    "\n",
    "# Output the splits\n",
    "for i, split in enumerate(splits, 1):\n",
    "    print(f\"Split {i}: {split}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf(tree_1, tree_2):\n",
    "    \"\"\"Count the number of different splits in a set of lists of splits.\n",
    "    \"\"\"\n",
    "    splits_1 = get_splits(tree_1)\n",
    "    splits_2 = get_splits(tree_2)\n",
    "    \n",
    "    diff_splits = 0\n",
    "    for split in splits_1:\n",
    "        if split not in splits_2:\n",
    "            diff_splits += 1\n",
    "    for split in splits_2:\n",
    "        if split not in splits_1:\n",
    "            diff_splits += 1\n",
    "    return diff_splits/2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ┌─G\n",
      "    ┌─A─┤\n",
      "    │   │   ┌─Y\n",
      "    │   └───┤\n",
      "──F─┤       └─Z\n",
      "    │   ┌─C\n",
      "    └─Q─┤\n",
      "        └─D\n",
      "        ┌─G\n",
      "    ┌─A─┤\n",
      "    │   │   ┌─Y\n",
      "    │   └───┤\n",
      "──F─┤       └─Z\n",
      "    │   ┌─C\n",
      "    └─E─┤\n",
      "        └─D\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[({'Y'}, {'Z'}),\n",
       " ({'G'}, {'Y', 'Z'}),\n",
       " ({'C'}, {'D'}),\n",
       " ({'A', 'G', 'Y', 'Z'}, {'C', 'D', 'Q'})]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trees = loads('((G,(Y,Z))A,(C,D)Q)F;((G,(Y,Z))A,(C,D)E)F;')\n",
    "tree_1 = trees[0]\n",
    "tree_2 = trees[1]\n",
    "\n",
    "splits_1 = get_splits(tree_1)\n",
    "splits_2 = get_splits(tree_2)\n",
    "\n",
    "print(tree_1.ascii_art())\n",
    "print(tree_2.ascii_art())\n",
    "\n",
    "splits_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 0 0 0]\n",
      " [1 0 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def splits_to_binary_matrix(splits, all_tips):\n",
    "    \"\"\"\n",
    "    Convert splits into a binary matrix.\n",
    "\n",
    "    Parameters:\n",
    "    splits: list of sets representing splits (each set is a group of tips)\n",
    "    all_tips: list of all tips (leaves)\n",
    "\n",
    "    Returns:\n",
    "    binary_matrix: Binary matrix representing splits\n",
    "    \"\"\"\n",
    "    # Number of splits and number of tips\n",
    "    n_splits = len(splits)\n",
    "    n_tips = len(all_tips)\n",
    "    \n",
    "    # Create a tip index mapping (tip to column index)\n",
    "    tip_index = {tip: i for i, tip in enumerate(all_tips)}\n",
    "    \n",
    "    # Initialize binary matrix with zeros\n",
    "    binary_matrix = np.zeros((n_splits, n_tips), dtype=int)\n",
    "    \n",
    "    # Fill in the matrix\n",
    "    for i, split in enumerate(splits):\n",
    "        for tip in split:\n",
    "            binary_matrix[i][tip_index[tip]] = 1  # Mark '1' for tips in the split\n",
    "    \n",
    "    return binary_matrix\n",
    "\n",
    "# Example usage\n",
    "all_tips = ['A', 'B', 'C', 'D', 'E']  # List of all tips\n",
    "splits = [{'A', 'B'}, {'A', 'C', 'D'}]  # Example splits\n",
    "\n",
    "binary_matrix = splits_to_binary_matrix(splits, all_tips)\n",
    "print(binary_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "\n",
    "\n",
    "def jaccard_similarity(split_1, split_2, n_tips, exponent, allow_conflict):\n",
    "    \"\"\"\n",
    "    Perform the matching of two sets of splits and compute their Jaccard similarity.\n",
    "\n",
    "    Args:\n",
    "        split_1 (numpy.ndarray): The first set of splits.\n",
    "        split_2 (numpy.ndarray): The second set of splits.\n",
    "        n_tips (list): The number of tips in the tree.\n",
    "        exponent (int): The exponent to use in the Jaccard similarity calculation.\n",
    "        allow_conflict (bool): Whether to allow conflicting splits.\n",
    "    \"\"\"\n",
    "    if split_1.shape[1] != split_2.shape[1]:\n",
    "        raise ValueError(\"Input splits must address the same number of tips.\")\n",
    "    \n",
    "    n_splits_1 = len(split_1)\n",
    "    n_splits_2 = len(split_2)\n",
    "    most_splits = max(n_splits_1, n_splits_2)\n",
    "    \n",
    "    max_score = 1e6\n",
    "\n",
    "    # Initialize the score matrix with the maximum score\n",
    "    score = np.full((most_splits, most_splits), max_score)\n",
    "\n",
    "    # Iterate over all splits in tree 1\n",
    "    for clade_a_ix in range(n_splits_1):\n",
    "        # Count number of tips in the split\n",
    "        n_tips_a = np.sum(split_1[clade_a_ix])\n",
    "        # Count number of tips not in this split\n",
    "        n_tips_not_a = n_tips - n_tips_a\n",
    "        \n",
    "        for clade_b_ix in range(n_splits_2):\n",
    "            clade_a_b = np.sum(np.bitwise_and(split_1[clade_b_ix],\n",
    "                                              split_2[clade_b_ix]))\n",
    "            \n",
    "            n_tips_b = np.sum(split_2[clade_b_ix])\n",
    "            n_tips_not_b = n_tips - n_tips_b\n",
    "            a_and_B = n_tips_a - clade_a_b\n",
    "            A_and_b = n_tips_b - clade_a_b\n",
    "            A_and_B = n_tips_not_b - a_and_B\n",
    "\n",
    "            if not allow_conflict and not (\n",
    "                clade_a_b == n_tips_a or a_and_B == n_tips_b or A_and_b == n_tips_not_a or A_and_B == n_tips_not_a):\n",
    "                score[clade_a_ix][clade_b_ix] = max_score\n",
    "            else:\n",
    "                A_or_b = n_tips - a_and_B\n",
    "                a_or_B = n_tips - A_and_b\n",
    "                a_or_b = n_tips - A_and_B\n",
    "                A_or_B = n_tips - clade_a_b\n",
    "\n",
    "                ars_ab = clade_a_b / a_or_b\n",
    "                ars_Ab = A_and_b / A_or_b\n",
    "                ars_aB = a_and_B / a_or_B\n",
    "                ars_AB = A_and_B / A_or_B\n",
    "\n",
    "                min_ars_both = min(ars_ab, ars_AB)\n",
    "                min_ars_either = min(ars_aB, ars_Ab)\n",
    "\n",
    "                if exponent == 1:\n",
    "                    score[clade_a_ix][clade_b_ix] = max_score - (max_score * max(min_ars_both, min_ars_either))\n",
    "                elif exponent == float('inf'):\n",
    "                    score[clade_a_ix][clade_b_ix] = 0 if min_ars_both == 1 or min_ars_either == 1 else max_score\n",
    "                else:\n",
    "                    score[clade_a_ix][clade_b_ix] = max_score - (max_score * (max(min_ars_both, min_ars_either) ** exponent))\n",
    "    \n",
    "    # Filling in extra rows/columns with max_score\n",
    "    score[n_splits_1:, :] = max_score\n",
    "    score[:, n_splits_2:] = max_score\n",
    "    \n",
    "    # Perform linear assignment to minimize the score\n",
    "    row_ind, col_ind = linear_sum_assignment(score)\n",
    "    \n",
    "    # Adjust by 2 - 2 * to retrieve zero in case of perfect match for RF\n",
    "    final_score = 2 - (max_score * most_splits - score[row_ind, col_ind].sum()) / max_score\n",
    "\n",
    "    # Prepare final matching\n",
    "    final_matching = np.full(n_splits_1, np.nan)\n",
    "    for i, match in enumerate(row_ind):\n",
    "        if match < n_splits_2:\n",
    "            final_matching[i] = match\n",
    "\n",
    "    return {\n",
    "        'score': final_score,\n",
    "        'matching': final_matching\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "all_tips = ['A', 'B', 'C', 'D', 'E']  # List of all tips\n",
    "splits_1 = [{'A', 'B', 'C'},{'D','E','C'}]  # Example splits\n",
    "splits_2 = [{'A', 'B', 'C'},{'D','E','C'}]  # Example splits\n",
    "\n",
    "binary_matrix_1 = splits_to_binary_matrix(splits_1, all_tips)\n",
    "binary_matrix_2 = splits_to_binary_matrix(splits_2, all_tips)\n",
    "\n",
    "x = np.array([[1, 0], [0, 1]])  # Example binary matrices for splits\n",
    "y = np.array([[1, 0], [0, 1]])\n",
    "n_tips = 5  # Example number of tips\n",
    "k = 1  # Example exponent\n",
    "allow_conflict = True\n",
    "\n",
    "result = jaccard_similarity(binary_matrix_1, binary_matrix_2, n_tips, k, allow_conflict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits_1 = get_splits(tree_1)\n",
    "splits_2 = get_splits(tree_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ┌─G\n",
      "    ┌─A─┤\n",
      "    │   │   ┌─Y\n",
      "    │   └───┤\n",
      "──F─┤       └─Z\n",
      "    │   ┌─C\n",
      "    └─Q─┤\n",
      "        └─D\n",
      "        ┌─G\n",
      "    ┌─A─┤\n",
      "    │   │   ┌─Y\n",
      "    │   └───┤\n",
      "──F─┤       └─Z\n",
      "    │   ┌─C\n",
      "    └─Q─┤\n",
      "        └─D\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[({'Y'}, {'Z'}),\n",
       " ({'G'}, {'Y', 'Z'}),\n",
       " ({'C'}, {'D'}),\n",
       " ({'A', 'G', 'Y', 'Z'}, {'C', 'D', 'Q'})]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trees = loads('((G,(Y,Z))A,(C,D)Q)F;((G,(Y,Z))A,(C,D)Q)F;')\n",
    "tree_1 = trees[0]\n",
    "tree_2 = trees[1]\n",
    "\n",
    "print(tree_1.ascii_art())\n",
    "print(tree_2.ascii_art())\n",
    "\n",
    "\n",
    "splits_1 = get_splits(tree_1)\n",
    "splits_2 = get_splits(tree_2)\n",
    "\n",
    "splits_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_intersection_proportion(set_1, set_2):\n",
    "    \"\"\"\n",
    "    Compute the proportion of the intersection of two sets.\n",
    "\n",
    "    Parameters:\n",
    "    set_1: First set\n",
    "    set_2: Second set\n",
    "\n",
    "    Returns:\n",
    "    proportion: Proportion of the intersection\n",
    "    \"\"\"\n",
    "    intersection = set_1.intersection(set_2)\n",
    "    union = set_1.union(set_2)\n",
    "    return len(intersection) / len(union)\n",
    "\n",
    "\n",
    "scores = []\n",
    "for split_1 in splits_1:\n",
    "    for split_2 in splits_2:\n",
    "        score_split_1 = []\n",
    "        # Iterate over every split and take the maximum score\n",
    "        score_split_1.append(max(compute_intersection_proportion(split_1[0], split_2[0]),\n",
    "                                 compute_intersection_proportion(split_1[1], split_2[1])))\n",
    "\n",
    "\n",
    "        # tips = list(set([value for inner_set in split_1 for value in inner_set] + [value for inner_set in split_2 for value in inner_set]))\n",
    "        # binary_matrix_1 = splits_to_binary_matrix(list(split_1), tips)\n",
    "        # binary_matrix_2 = splits_to_binary_matrix(list(split_2), tips)\n",
    "        # score = jaccard_similarity(binary_matrix_1, binary_matrix_2, len(tips), 1, False)[\"score\"]\n",
    "        # if score != 0:\n",
    "        #     print(f\"Split {split_1} and {split_2} have a Jaccard similarity of {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_1_right, split_1_left = splits_1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "{'Y'}\n",
      "{'Z'}\n",
      "----\n",
      "---\n",
      "{'G'}\n",
      "{'Z', 'Y'}\n",
      "----\n",
      "---\n",
      "{'C'}\n",
      "{'D'}\n",
      "----\n",
      "---\n",
      "{'A', 'G', 'Z', 'Y'}\n",
      "{'D', 'C', 'Q'}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "scores = {}\n",
    "for ix_1, (split_1_left, split_1_right) in enumerate(splits_1):\n",
    "    print(\"---\")\n",
    "    print(split_1_left)\n",
    "    print(split_1_right)\n",
    "    print(\"----\")\n",
    "    scores[ix_1] = {}\n",
    "    for ix, (split_2_left, split_1_right) in enumerate(splits_2):\n",
    "        scores[ix_1][ix] = max(\n",
    "            min(compute_intersection_proportion(split_1_left, split_2_left),\n",
    "                compute_intersection_proportion(split_1_right, split_1_right)),\n",
    "            min(compute_intersection_proportion(split_1_left, split_1_right),\n",
    "                                compute_intersection_proportion(split_1_right, split_2_left)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = np.array([[scores[i][j] for j in range(len(scores))] for i in range(len(scores))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "row_ind, col_ind = linear_sum_assignment(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.0)"
      ]
     },
     "execution_count": 683,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[row_ind, col_ind].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import linear_sum_assignment\n",
    "from newick import loads\n",
    "import numpy as np \n",
    "\n",
    "\n",
    "def load_tree(newick_str):\n",
    "    \"\"\"Load the first tree of the newick string.\n",
    "    Careful, if there are several trees, only the first one is loaded.\n",
    "    \"\"\"\n",
    "    return loads(newick_str)[0]\n",
    "\n",
    "\n",
    "def get_nodes(node):\n",
    "    \"\"\"Get the nodes under a leaf.\n",
    "    \"\"\"\n",
    "    if node.is_leaf:\n",
    "        return {node.name}\n",
    "\n",
    "    leaves = set()\n",
    "\n",
    "    for child in node.descendants:\n",
    "        leaves.update(get_nodes(child))\n",
    "    if node.name:\n",
    "        leaves.add(node.name)\n",
    "    return leaves\n",
    "\n",
    "\n",
    "def get_splits(node):\n",
    "    \"\"\"\n",
    "    Get the splits recursively at each node.\n",
    "    \"\"\"\n",
    "    splits = []\n",
    "\n",
    "    if node.is_leaf:\n",
    "        return splits\n",
    "\n",
    "    current_leaves = []\n",
    "    for descendant in node.descendants:\n",
    "        current_leaves.append(get_nodes(descendant))\n",
    "        splits += get_splits(descendant)\n",
    "    splits.append(tuple(current_leaves))\n",
    "\n",
    "    return splits\n",
    "\n",
    "\n",
    "def compute_intersection_proportion(set_1, set_2, order=1):\n",
    "    \"\"\"\n",
    "    Compute the proportion of the intersection of two sets.\n",
    "\n",
    "    Parameters:\n",
    "    set_1: First set\n",
    "    set_2: Second set\n",
    "\n",
    "    Returns:\n",
    "    proportion: Proportion of the intersection\n",
    "    \"\"\"\n",
    "    intersection = set_1.intersection(set_2)\n",
    "    union = set_1.union(set_2)\n",
    "    if order == 1:\n",
    "        # Computation for the Nye similarity\n",
    "        return len(intersection) / len(union)\n",
    "    else:\n",
    "        # Computation for the Böcker similarity\n",
    "        return 2 - 2 * (len(intersection) / len(union))**order\n",
    "\n",
    "\n",
    "def jaccard_similarity(split_1, split_2, order=1):\n",
    "    \"\"\"Compute the score between two splits.\n",
    "    \"\"\"\n",
    "    split_1_left, split_1_right = split_1\n",
    "    split_2_left, split_2_right = split_2\n",
    "    return max(\n",
    "        min(compute_intersection_proportion(split_1_left, split_2_left, order=order),\n",
    "            compute_intersection_proportion(split_1_right, split_2_right, order=order)),\n",
    "        min(compute_intersection_proportion(split_1_left, split_2_right, order=order),\n",
    "            compute_intersection_proportion(split_1_right, split_2_left, order=order)))\n",
    "\n",
    "\n",
    "def split_similarity(splits_1, splits_2, score_computer, *args, **kwargs):\n",
    "    \"\"\"Given two slides, define the generalized Robinson-Foulds distance\n",
    "    using the similarity given as input in the score_computer function.\n",
    "    \"\"\"\n",
    "    scores = {}\n",
    "    for ix_1, split_1 in enumerate(splits_1):\n",
    "        scores[ix_1] = {}\n",
    "        for ix, split_2 in enumerate(splits_2):\n",
    "            scores[ix_1][ix] = score_computer(split_1,\n",
    "                                             split_2,\n",
    "                                             *args, **kwargs)\n",
    "    # This can be optimized\n",
    "    scores_array = np.array([[scores[i][j] for j in range(len(scores))] for i in range(len(scores))])\n",
    "    row_ind, col_ind = linear_sum_assignment(scores_array)\n",
    "    return scores_array[row_ind, col_ind].sum()\n",
    "    \n",
    "\n",
    "def rf_generalized(tree_1_str,\n",
    "                   tree_2_str, \n",
    "                   score_computer,\n",
    "                   *args, **kwargs):\n",
    "    \"\"\"Return the generalized Robinson's Foulds jaccard distance.\"\"\"\n",
    "    tree_1 = load_tree(tree_1_str)\n",
    "    tree_2 = load_tree(tree_2_str)\n",
    "    \n",
    "    splits_1 = get_splits(tree_1)\n",
    "    splits_2 = get_splits(tree_2)\n",
    "    \n",
    "    return split_similarity(splits_1, splits_2, score_computer, *args, **kwargs)\n",
    "\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "\n",
    "def get_unique_values_splits(splits_1, splits_2):\n",
    "    \"\"\"\n",
    "    Get the number of distinct leaves in two splits.\n",
    "    \"\"\"\n",
    "    # Combine the two lists into one\n",
    "    combined_data = splits_1 + splits_2\n",
    "    \n",
    "    # Flatten the list of tuples into one list of sets, then apply union across all sets\n",
    "    all_sets = [set1.union(set2) for set1, set2 in combined_data]\n",
    "    \n",
    "    # Use reduce to apply union across all sets\n",
    "    unique_values = reduce(set.union, all_sets)\n",
    "    \n",
    "    return len(unique_values)\n",
    "\n",
    "\n",
    "def matching_split(split_1, split_2):\n",
    "    \"\"\"Compute the score between two splits.\n",
    "    \"\"\"\n",
    "    split_1_left, split_1_right = split_1\n",
    "    split_2_left, split_2_right = split_2\n",
    "    \n",
    "    len_tree = get_unique_values_splits(\n",
    "        [split_1],\n",
    "        [split_2]\n",
    "    )\n",
    "    return len_tree - max(\n",
    "        len(split_1_left.intersection(split_2_left)) + len(split_2_right.intersection(split_2_right)),\n",
    "        len(split_1_left.intersection(split_2_right)) + len(split_1_right.intersection(split_2_left))\n",
    "    )            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_generalized('((G,(Y,Z))A,(C,D)Q)F;', \n",
    "               \"((G,(Y,Z))A,(C,D)Q)F;\",\n",
    "               score_computer=matching_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def double_factorial(n):\n",
    "    \"\"\"Define the double factorial.\"\"\"\n",
    "    if n <= 0:\n",
    "        return 1\n",
    "    return math.prod(range(n, 0, -2))\n",
    "\n",
    "\n",
    "def P_Phy(split):\n",
    "    \"\"\"Compute the probability of apparition of a split.\"\"\"\n",
    "    split_1_left, split_1_right = split\n",
    "\n",
    "    X_len = get_unique_values_splits(splits_1, [])\n",
    "\n",
    "    numerator = (double_factorial(2 * len(split_1_left) - 3) * \n",
    "                 double_factorial(2 * len(split_1_right) - 3))\n",
    "    \n",
    "    denominator = double_factorial(2 * X_len - 5)\n",
    "\n",
    "    return numerator / denominator\n",
    "\n",
    "\n",
    "def phylogenetic_information_content(split):\n",
    "    \"\"\"Compute the phylogenetic information content.\"\"\"\n",
    "    return -math.log(P_Phy(split))\n",
    "\n",
    "\n",
    "# Function to compute P_Phy for given sets S1 and S2\n",
    "def probability_splits(split_1, split_2):\n",
    "    \"\"\"Compute the probability of apparition of two splits.\n",
    "    \"\"\"\n",
    "    split_1_left, split_1_right = split_1\n",
    "    split_2_left, _ = split_2\n",
    "    X_len = get_unique_values_splits([split_1], [split_2])\n",
    "\n",
    "    numerator = (double_factorial(2 * (len(split_1_right) + 1) - 5) * \n",
    "                 double_factorial(2 * (len(split_2_left) + 1) - 5) * \n",
    "                 double_factorial(2 * (len(split_1_left) - len(split_2_left) + 2) - 5))\n",
    "\n",
    "    denominator = double_factorial(2 * X_len - 5)\n",
    "\n",
    "    return -math.log(numerator / denominator)\n",
    "\n",
    "\n",
    "def shared_phylogenetic_information_score(split_1, split_2):\n",
    "    \"\"\"Compute the shared phylogenetic information of two splits.\n",
    "    \"\"\"\n",
    "    if are_splits_incompatible(split_1, split_2):\n",
    "        return 0\n",
    "    return phylogenetic_information_content(split_1) + \\\n",
    "        phylogenetic_information_content(split_2) - \\\n",
    "        probability_splits(split_1, split_2)\n",
    "\n",
    "def shared_phylogenetic_information(tree_1, tree_2):\n",
    "    return rf_generalized(\n",
    "        tree_1,\n",
    "        tree_2,\n",
    "        score_computer=shared_phylogenetic_information_score)\n",
    "\n",
    "\n",
    "def mutual_clustering_information(tree_1, tree_2):\n",
    "    \"\"\"Given two trees, compute the shared phylogenetic information between the trees.\n",
    "    \"\"\"\n",
    "    splits_1 = get_splits(tree_1)\n",
    "    splits_2 = get_splits(tree_2)\n",
    "    \n",
    "    return \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_1_left, split_1_right = splits_1[0]\n",
    "split_2_left, split_1_right = splits_2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matching_split_information(split_1, split_2):\n",
    "    \"\"\"Define the matching split information score (MSI) between two splits.\"\"\"\n",
    "    split_1_left, split_1_right = split_1\n",
    "    split_2_left, split_2_right = split_2\n",
    "    return max(\n",
    "    phylogenetic_information_content((split_1_left.intersection(split_2_left), split_1_right.intersection(split_2_right))),\n",
    "    phylogenetic_information_content((split_1_left.intersection(split_2_right), split_1_right.intersection(split_2_left)))\n",
    ")\n",
    "\n",
    "def shared_phylogenetic_information(split_1, split_2):\n",
    "    \"\"\"Compute the shared phylogenetic information of two splits.\n",
    "    \"\"\"\n",
    "    if are_splits_incompatible(split_1, split_2):\n",
    "        return 0\n",
    "    return phylogenetic_information_content(split_1) + \\\n",
    "        phylogenetic_information_content(split_2) - \\\n",
    "        probability_splits(split_1, split_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(27.404739709974972)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_generalized('(((E,M)Y,Z)A,(C,D)Q)F;',\n",
    "                \"((G,(Y,Z))A,(C,E)Q)F;\",\n",
    "                score_computer=matching_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(24.696689508872762)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_generalized('(((E,M)Y,Z)A,(C,D)Q)F;',\n",
    "                \"((G,(Y,Z))A,(C,E)Q)F;\",\n",
    "                score_computer=shared_phylogenetic_information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loads' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mloads\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m((G,(Y,Z))A,(C,D)Q)F;((G,(Y,Z))A,(C,D)Q)F;\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m tree_1 \u001b[38;5;241m=\u001b[39m trees[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      3\u001b[0m tree_2 \u001b[38;5;241m=\u001b[39m trees[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'loads' is not defined"
     ]
    }
   ],
   "source": [
    "trees = loads('((G,(Y,Z))A,(C,D)Q)F;((G,(Y,Z))A,(C,D)Q)F;')\n",
    "tree_1 = trees[0]\n",
    "tree_2 = trees[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ┌─E\n",
      "        ┌─Y─┤\n",
      "    ┌─A─┤   └─M\n",
      "──F─┤   └─Z\n",
      "    │   ┌─C\n",
      "    └─Q─┤\n",
      "        └─D\n",
      "        ┌─G\n",
      "    ┌─A─┤\n",
      "    │   │   ┌─Y\n",
      "    │   └───┤\n",
      "──F─┤       └─Z\n",
      "    │   ┌─C\n",
      "    └─Q─┤\n",
      "        └─D\n"
     ]
    }
   ],
   "source": [
    "trees = loads('(((E,M)Y,Z)A,(C,D)Q)F;((G,(Y,Z))A,(C,D)Q)F;')\n",
    "tree_1 = trees[0]\n",
    "tree_2 = trees[1]\n",
    "\n",
    "print(tree_1.ascii_art())\n",
    "print(tree_2.ascii_art())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The splits are incompatible.\n"
     ]
    }
   ],
   "source": [
    "def are_splits_incompatible(split_1, split_2):\n",
    "    \"\"\"\n",
    "    Determines if two splits are incompatible.\n",
    "    A split is represented as a tuple of two sets, where each set is a group of taxa.\n",
    "    For example, split1 = ({'A', 'B'}, {'C', 'D'}) represents the split {A, B} | {C, D}.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Unpack the splits\n",
    "    split_1_left, split_1_right = split_1\n",
    "    split_2_left, split_2_right = split_2\n",
    "    \n",
    "    # Check for incompatibility: There should not be overlap between a group in one split\n",
    "    # and both groups in the other split.\n",
    "    \n",
    "    # Group 1 of split 1 should not overlap with both groups of split 2\n",
    "    if (split_1_left & split_2_left and split_1_left & split_2_right):\n",
    "        return True\n",
    "    # Group 2 of split 1 should not overlap with both groups of split 2\n",
    "    if (split_1_right & split_2_left and split_1_right & split_2_right):\n",
    "        return True\n",
    "    \n",
    "    # If no conflicts were found, the splits are compatible\n",
    "    return False\n",
    "\n",
    "# Example splits\n",
    "split1 = ({'A', 'B'}, {'C', 'D'})\n",
    "split2 = ({'A', 'C'}, {'B', 'D'})\n",
    "\n",
    "# Check if the splits are incompatible\n",
    "if are_splits_incompatible(split1, split2):\n",
    "    print(\"The splits are incompatible.\")\n",
    "else:\n",
    "    print(\"The splits are compatible.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the graph edit distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree Edit Distance: 3\n"
     ]
    }
   ],
   "source": [
    "import newick\n",
    "\n",
    "def tree_edit_distance(tree1, tree2):\n",
    "    \"\"\"\n",
    "    Recursively calculates the tree edit distance between two trees,\n",
    "    accounting for node names and structure.\n",
    "    \"\"\"\n",
    "    if tree1.name != tree2.name:\n",
    "        # Node substitution cost (if names differ)\n",
    "        cost = 1\n",
    "    else:\n",
    "        cost = 0\n",
    "\n",
    "    # Get children of both nodes\n",
    "    children1 = tree1.descendants\n",
    "    children2 = tree2.descendants\n",
    "\n",
    "    # Calculate insertion or deletion costs for unbalanced children\n",
    "    ins_del_cost = abs(len(children1) - len(children2))\n",
    "\n",
    "    # Recursive structure comparison for all pairs of children\n",
    "    sub_cost = 0\n",
    "    for c1, c2 in zip(children1, children2):\n",
    "        sub_cost += tree_edit_distance(c1, c2)\n",
    "\n",
    "    # Total cost includes substitution, insertion/deletion, and recursive structure costs\n",
    "    total_cost = cost + ins_del_cost + sub_cost\n",
    "    return total_cost\n",
    "\n",
    "# Example usage\n",
    "tree_newick_1 = \"((A,B),C)F;\"\n",
    "tree_newick_2 = \"((A,C),F)B;\"\n",
    "\n",
    "# Load trees from Newick strings\n",
    "tree1 = newick.loads(tree_newick_1)[0]\n",
    "tree2 = newick.loads(tree_newick_2)[0]\n",
    "\n",
    "# Calculate tree edit distance\n",
    "distance = tree_edit_distance(tree1, tree2)\n",
    "print(\"Tree Edit Distance:\", distance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ┌─A\n",
      "    ┌───┤\n",
      "──F─┤   └─B\n",
      "    └─C\n",
      "        ┌─A\n",
      "    ┌───┤\n",
      "──B─┤   └─C\n",
      "    └─F\n"
     ]
    }
   ],
   "source": [
    "print(tree1.ascii_art())\n",
    "\n",
    "print(tree2.ascii_art())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing affinity matrixes and the corresponding euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import newick\n",
    "from newick import loads\n",
    "\n",
    "\n",
    "def load_tree(newick_str):\n",
    "    \"\"\"Load the first tree of the newick string.\n",
    "    Careful, if there are several trees, only the first one is loaded.\n",
    "    \"\"\"\n",
    "    return loads(newick_str)[0]\n",
    "\n",
    "\n",
    "def build_edges_from_tree(node):\n",
    "    \"\"\"\n",
    "    Recursively build edges from the tree structure.\n",
    "    \"\"\"\n",
    "    edges = []\n",
    "    if node.name is not None:  # Ensure the node has a name\n",
    "        for child in node.descendants:\n",
    "            if child.name is not None:  # Ensure the child has a name\n",
    "                edges.append((node.name, child.name))  # Add edge\n",
    "                edges.extend(build_edges_from_tree(child))  # Recur for child\n",
    "    return edges\n",
    "\n",
    "\n",
    "def create_adjacency_matrix(tree):\n",
    "    \"\"\"Create an adjacency matrix from a tree.\n",
    "    \"\"\"\n",
    "    # Build edges from the tree\n",
    "    edges = build_edges_from_tree(tree)\n",
    "\n",
    "    # Extract unique nodes\n",
    "    nodes = list(set([node for edge in edges for node in edge]))\n",
    "\n",
    "    # Initialize the adjacency matrix\n",
    "    n = len(nodes)\n",
    "    matrix = np.zeros((n, n), dtype=int)\n",
    "\n",
    "    # Fill the adjacency matrix\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if (nodes[i], nodes[j]) in edges or (nodes[j], nodes[i]) in edges:\n",
    "                matrix[i, j] = 1  # Mark as connected\n",
    "\n",
    "    return nodes, matrix\n",
    "\n",
    "\n",
    "def compute_distance_adjacency_matrix(matrix_1, matrix_2, degree=2):\n",
    "    \"\"\"Compute the distance between two adjacency matrices.\n",
    "    Possible distances include the l1 and the l2 norm.\n",
    "    \"\"\"\n",
    "    return ((matrix_1 - matrix_2) ** degree).mean() ** (1/degree)\n",
    "\n",
    "\n",
    "def adjacency_matrix_distance(tree_1_str, tree_2_str):\n",
    "    \"\"\"Compute the distance between two trees using adjacency matrices.\n",
    "    Careful, all nodes of the tree must be named for this distance to be computed,\n",
    "    including the root node.\n",
    "    \"\"\"\n",
    "    # Load the trees from the Newick strings\n",
    "    tree_1 = load_tree(tree_1_str)\n",
    "    tree_2 = load_tree(tree_2_str)\n",
    "\n",
    "    # Create adjacency matrices from the trees\n",
    "    nodes_1, matrix_1 = create_adjacency_matrix(tree_1)\n",
    "    nodes_2, matrix_2 = create_adjacency_matrix(tree_2)\n",
    "\n",
    "    # Compute the distance between the adjacency matrices\n",
    "    distance = compute_distance_adjacency_matrix(matrix_1, matrix_2)\n",
    "    return distance\n",
    "\n",
    "\n",
    "\n",
    "# # Example Newick string\n",
    "# newick_str = \"((A,B)G, (C, (D, E)X))F;\"\n",
    "\n",
    "# # Create adjacency matrix from the Newick string\n",
    "# nodes, adjacency_matrix = create_adjacency_matrix(newick_str)\n",
    "\n",
    "# # Display the results\n",
    "# if nodes and adjacency_matrix is not None:\n",
    "#     print(\"Nodes:\", nodes)\n",
    "#     print(\"\\nAdjacency Matrix:\")\n",
    "#     print(\"  \" + \" \".join(nodes))\n",
    "#     for i, row in enumerate(adjacency_matrix):\n",
    "#         print(nodes[i] + \" \" + \" \".join(map(str, row.astype(int))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.0)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_newick_1 = \"((A,E)D,B)F;\"\n",
    "tree_newick_2 = \"((A,E)D,B)F;\"\n",
    "\n",
    "adjacency_matrix_distance(tree_newick_1, tree_newick_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ┌─A\n",
      "    ┌─D─┤\n",
      "──F─┤   └─E\n",
      "    └─B\n",
      "        ┌─A\n",
      "    ┌─D─┤\n",
      "──F─┤   └─E\n",
      "    └─B\n"
     ]
    }
   ],
   "source": [
    "print(loads(tree_newick_1)[0].ascii_art())\n",
    "print(loads(tree_newick_2)[0].ascii_art())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import newick\n",
    "from newick import loads\n",
    "\n",
    "\n",
    "def load_tree(newick_str):\n",
    "    \"\"\"Load the first tree of the newick string.\n",
    "    Careful, if there are several trees, only the first one is loaded.\n",
    "    \"\"\"\n",
    "    return loads(newick_str)[0]\n",
    "\n",
    "\n",
    "def build_edges_from_tree(node):\n",
    "    \"\"\"\n",
    "    Recursively build edges from the tree structure.\n",
    "    \"\"\"\n",
    "    edges = []\n",
    "    if node.name is not None:  # Ensure the node has a name\n",
    "        for child in node.descendants:\n",
    "            if child.name is not None:  # Ensure the child has a name\n",
    "                edges.append((node.name, child.name))  # Add edge\n",
    "                edges.extend(build_edges_from_tree(child))  # Recur for child\n",
    "    return edges\n",
    "\n",
    "\n",
    "def create_adjacency_matrix(tree):\n",
    "    \"\"\"Create an adjacency matrix from a tree.\n",
    "    \"\"\"\n",
    "    # Build edges from the tree\n",
    "    edges = build_edges_from_tree(tree)\n",
    "\n",
    "    # Extract unique nodes\n",
    "    nodes = list(set([node for edge in edges for node in edge]))\n",
    "\n",
    "    # Initialize the adjacency matrix\n",
    "    n = len(nodes)\n",
    "    matrix = np.zeros((n, n), dtype=int)\n",
    "\n",
    "    # Fill the adjacency matrix\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if (nodes[i], nodes[j]) in edges or (nodes[j], nodes[i]) in edges:\n",
    "                matrix[i, j] = 1  # Mark as connected\n",
    "\n",
    "    return nodes, matrix\n",
    "\n",
    "\n",
    "def compute_distance_adjacency_matrix(matrix_1, matrix_2, degree=2):\n",
    "    \"\"\"Compute the distance between two adjacency matrices.\n",
    "    Possible distances include the l1 and the l2 norm.\n",
    "    \"\"\"\n",
    "    return ((matrix_1 - matrix_2) ** degree).mean() ** (1/degree)\n",
    "\n",
    "\n",
    "def adjacency_matrix_distance(tree_1_str, tree_2_str):\n",
    "    \"\"\"Compute the distance between two trees using adjacency matrices.\n",
    "    Careful, all nodes of the tree must be named for this distance to be computed,\n",
    "    including the root node.\n",
    "    \"\"\"\n",
    "    # Load the trees from the Newick strings\n",
    "    tree_1 = load_tree(tree_1_str)\n",
    "    tree_2 = load_tree(tree_2_str)\n",
    "\n",
    "    # Create adjacency matrices from the trees\n",
    "    nodes_1, matrix_1 = create_adjacency_matrix(tree_1)\n",
    "    nodes_2, matrix_2 = create_adjacency_matrix(tree_2)\n",
    "\n",
    "    # Compute the distance between the adjacency matrices\n",
    "    distance = compute_distance_adjacency_matrix(matrix_1, matrix_2)\n",
    "    return distance\n",
    "\n",
    "\n",
    "\n",
    "# # Example Newick string\n",
    "# newick_str = \"((A,B)G, (C, (D, E)X))F;\"\n",
    "\n",
    "# # Create adjacency matrix from the Newick string\n",
    "# nodes, adjacency_matrix = create_adjacency_matrix(newick_str)\n",
    "\n",
    "# # Display the results\n",
    "# if nodes and adjacency_matrix is not None:\n",
    "#     print(\"Nodes:\", nodes)\n",
    "#     print(\"\\nAdjacency Matrix:\")\n",
    "#     print(\"  \" + \" \".join(nodes))\n",
    "#     for i, row in enumerate(adjacency_matrix):\n",
    "#         print(nodes[i] + \" \" + \" \".join(map(str, row.astype(int))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ┌─A\n",
      "    ┌─G─┤\n",
      "    │   └─B\n",
      "──F─┤\n",
      "    │   ┌─C\n",
      "    └───┤\n",
      "        │   ┌─D\n",
      "        └─X─┤\n",
      "            └─E\n"
     ]
    }
   ],
   "source": [
    "print(newick.loads(newick_str)[0].ascii_art())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement the signed similarity between two trees (see Roos and Hekkila)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score de similarité de Roos: 14.0\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import newick\n",
    "\n",
    "def build_node_paths(tree, path=None, paths=None):\n",
    "    \"\"\"\n",
    "    Recursively build the paths to each node in the tree.\n",
    "    \"\"\"\n",
    "    if paths is None:\n",
    "        paths = {}\n",
    "    if path is None:\n",
    "        path = []\n",
    "    \n",
    "    if tree.name:\n",
    "        paths[tree.name] = path + [tree.name]\n",
    "    \n",
    "    for child in tree.descendants:\n",
    "        build_node_paths(child, path + [tree.name], paths)\n",
    "    return paths\n",
    "\n",
    "\n",
    "def calculate_distance(paths, node1, node2):\n",
    "    \"\"\"\n",
    "    Compute the distances in terms of edges between two nodes.\n",
    "    \"\"\"\n",
    "    path1 = paths.get(node1, [])\n",
    "    path2 = paths.get(node2, [])\n",
    "\n",
    "    # Find the nearest common ancestor\n",
    "    common_ancestor = None\n",
    "    for u, v in zip(path1, path2):\n",
    "        if u == v:\n",
    "            common_ancestor = u\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    # Compute the distance as the sum of the distances to the common ancestor\n",
    "    # Total path - path to reach ancestor - 1 (to avoid counting the common ancestor twice)                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
    "    distance = (len(path1) - path1.index(common_ancestor) - 1) + (len(path2) - path2.index(common_ancestor) - 1)\n",
    "    return distance\n",
    "\n",
    "def compute_u(tree_paths_tree1,\n",
    "                tree_paths_tree2, \n",
    "                A, B, C):\n",
    "    \"\"\"\n",
    "    Compute the u value for a triplet of nodes taken from tree 1 and tree 2.\n",
    "    \"\"\"\n",
    "    # Distances dans l'arbre testé\n",
    "    d_tree1_AB = calculate_distance(tree_paths_tree1, A, B)\n",
    "    d_tree1_AC = calculate_distance(tree_paths_tree1, A, C)\n",
    "    # Distances dans l'arbre de référence\n",
    "    d_tree2_AB = calculate_distance(tree_paths_tree2, A, B)\n",
    "    d_tree2_AC = calculate_distance(tree_paths_tree2, A, C)\n",
    "    \n",
    "    # Calcul de la fonction u\n",
    "    sign_test = int(d_tree1_AB - d_tree1_AC > 0) - int(d_tree1_AB - d_tree1_AC < 0)\n",
    "    sign_ref = int(d_tree2_AB - d_tree2_AC > 0) - int(d_tree2_AB - d_tree2_AC < 0)\n",
    "    u_value = 1 - 0.5 * abs(sign_test - sign_ref)\n",
    "    return u_value\n",
    "\n",
    "\n",
    "def compute_roos_similarity(tree_1, tree_2):\n",
    "    \"\"\"Compute the Roos similarity between two trees.\n",
    "    \"\"\"\n",
    "    # Compute the paths for every node in the tree\n",
    "    tree_paths_1 = build_node_paths(tree_1)\n",
    "    tree_paths_2 = build_node_paths(tree_2)\n",
    "    \n",
    "    # List the common nodes in the tree\n",
    "    common_nodes = set(tree_paths_1.keys()).intersection(tree_paths_2.keys())\n",
    "    \n",
    "    # Compute for each triplet the u value\n",
    "    S = 0\n",
    "    for A, B, C in itertools.combinations(common_nodes, 3):\n",
    "        S += compute_u(tree_paths_1, tree_paths_2, A, B, C)\n",
    "    \n",
    "    # Adjust the score for identical trees to zero\n",
    "    # Perfect score is the case were each triplet has a u value of 1\n",
    "    max_score = len(list(itertools.combinations(common_nodes, 3)))\n",
    "    similarity_score = max_score - S  # Subtract to reflect dissimilarity\n",
    "    \n",
    "    return similarity_score\n",
    "\n",
    "def roos_similarity(tree_1_str, tree_2_str):\n",
    "    \"\"\"\n",
    "    Compute the Roos similarity between two trees.\n",
    "    \"\"\"\n",
    "    # Charger les arbres depuis les chaînes Newick\n",
    "    tree_1 = newick.loads(tree_1_str)[0]\n",
    "    tree_2 = newick.loads(tree_2_str)[0]\n",
    "    \n",
    "    return compute_roos_similarity(tree_1, tree_2)\n",
    "\n",
    "\n",
    "# Exemples de chaînes Newick pour l'arbre testé et l'arbre de référence\n",
    "newick_str_test = \"((A,B)X, (C, (D, E)Z)U)F;\"\n",
    "newick_str_ref = \"((A,X)B, (C, (D, E)Z)U)F;\"\n",
    "\n",
    "# Calculer la similarité de Roos\n",
    "similarity_score = roos_similarity(newick_str_test, newick_str_ref)\n",
    "\n",
    "# Afficher le score de similarité\n",
    "print(\"Score de similarité de Roos:\", similarity_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ┌─A\n",
      "    ┌─X─┤\n",
      "    │   └─B\n",
      "──F─┤\n",
      "    │   ┌─C\n",
      "    └─U─┤\n",
      "        │   ┌─D\n",
      "        └─Z─┤\n",
      "            └─E\n"
     ]
    }
   ],
   "source": [
    "print(newick.loads(newick_str_test)[0].ascii_art())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ┌─A\n",
      "    ┌─X─┤\n",
      "    │   └─B\n",
      "──F─┤\n",
      "    │   ┌─C\n",
      "    └─U─┤\n",
      "        │   ┌─D\n",
      "        └─Z─┤\n",
      "            └─E\n"
     ]
    }
   ],
   "source": [
    "print(newick.loads(newick_str_ref)[0].ascii_art())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_1 = \"(((A,B)X,(E,G)H)I,((C,D)Y,(M,N)O)Z);\"\n",
    "tree_2 = \"(((A,C)X,(P,Q)H)I,((F,L)Y,(R,S)O)Z);\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ┌─A\n",
      "        ┌─X─┤\n",
      "    ┌─Y─┤   └─B\n",
      "──Z─┤   └─C\n",
      "    └─D\n"
     ]
    }
   ],
   "source": [
    "print(newick.loads(\"(((A,B)X,C)Y,D)Z;\")[0].ascii_art())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ┌─A\n",
      "        ┌─X─┤\n",
      "        │   └─C\n",
      "    ┌─I─┤\n",
      "    │   │   ┌─P\n",
      "    │   └─H─┤\n",
      "    │       └─Q\n",
      "────┤\n",
      "    │       ┌─F\n",
      "    │   ┌─Y─┤\n",
      "    │   │   └─L\n",
      "    └─Z─┤\n",
      "        │   ┌─R\n",
      "        └─O─┤\n",
      "            └─S\n"
     ]
    }
   ],
   "source": [
    "print(newick.loads(tree_2)[0].ascii_art())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from stemmadist.dists.rf.rf import rf_distance\n",
    "\n",
    "rf_distance(tree_1, tree_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting networkx\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: networkx\n",
      "Successfully installed networkx-3.4.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ┌─A\n",
      "    ┌─M─┤\n",
      "    │   └─B\n",
      "──F─┤\n",
      "    │   ┌─D\n",
      "    └─X─┤\n",
      "        └─L\n",
      "Nodes: ['F', 'M', Node(\"F\"), 'A', Node(\"M\"), 'B', 'X', 'D', Node(\"X\"), 'L']\n",
      "Edges: [(Node(\"F\"), 'M'), (Node(\"F\"), 'X'), (Node(\"M\"), 'A'), (Node(\"M\"), 'B'), (Node(\"X\"), 'D'), (Node(\"X\"), 'L')]\n",
      "        ┌─A\n",
      "    ┌─X─┤\n",
      "    │   └─B\n",
      "──F─┤\n",
      "    │   ┌─D\n",
      "    └─M─┤\n",
      "        └─L\n",
      "Nodes: ['F', 'X', Node(\"F\"), 'A', Node(\"X\"), 'B', 'M', 'D', Node(\"M\"), 'L']\n",
      "Edges: [(Node(\"F\"), 'X'), (Node(\"F\"), 'M'), (Node(\"X\"), 'A'), (Node(\"X\"), 'B'), (Node(\"M\"), 'D'), (Node(\"M\"), 'L')]\n",
      "F F\n",
      "F X\n",
      "F None\n",
      "F A\n",
      "F None\n",
      "F B\n",
      "F M\n",
      "F D\n",
      "F None\n",
      "F L\n",
      "M F\n",
      "M X\n",
      "M None\n",
      "M A\n",
      "M None\n",
      "M B\n",
      "M M\n",
      "M D\n",
      "M None\n",
      "M L\n",
      "None F\n",
      "None X\n",
      "None None\n",
      "None A\n",
      "None None\n",
      "None B\n",
      "None M\n",
      "None D\n",
      "None None\n",
      "None L\n",
      "A F\n",
      "A X\n",
      "A None\n",
      "A A\n",
      "A None\n",
      "A B\n",
      "A M\n",
      "A D\n",
      "A None\n",
      "A L\n",
      "None F\n",
      "None X\n",
      "None None\n",
      "None A\n",
      "None None\n",
      "None B\n",
      "None M\n",
      "None D\n",
      "None None\n",
      "None L\n",
      "B F\n",
      "B X\n",
      "B None\n",
      "B A\n",
      "B None\n",
      "B B\n",
      "B M\n",
      "B D\n",
      "B None\n",
      "B L\n",
      "X F\n",
      "X X\n",
      "X None\n",
      "X A\n",
      "X None\n",
      "X B\n",
      "X M\n",
      "X D\n",
      "X None\n",
      "X L\n",
      "D F\n",
      "D X\n",
      "D None\n",
      "D A\n",
      "D None\n",
      "D B\n",
      "D M\n",
      "D D\n",
      "D None\n",
      "D L\n",
      "None F\n",
      "None X\n",
      "None None\n",
      "None A\n",
      "None None\n",
      "None B\n",
      "None M\n",
      "None D\n",
      "None None\n",
      "None L\n",
      "L F\n",
      "L X\n",
      "L None\n",
      "L A\n",
      "L None\n",
      "L B\n",
      "L M\n",
      "L D\n",
      "L None\n",
      "L L\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import newick\n",
    "\n",
    "def newick_to_networkx(newick_str):\n",
    "    # Parse the Newick tree\n",
    "    tree = newick.loads(newick_str)[0]  # loads returns a list of trees; we use the first\n",
    "    print(tree.ascii_art())\n",
    "    # Initialize an empty directed NetworkX graph\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    # Recursive function to add nodes and edges to the graph\n",
    "    def add_edges(node, parent=None):\n",
    "        current_node = node.name or id(node)\n",
    "        # Add the current node\n",
    "        G.add_node(current_node, label=node.name)  # Internal nodes without names get a unique object\n",
    "        if parent is not None:\n",
    "            G.add_edge(parent, current_node)\n",
    "\n",
    "        # Recursively add children\n",
    "        for child in node.descendants:\n",
    "            add_edges(child, node)\n",
    "\n",
    "    # Start building the graph from the root of the tree\n",
    "    add_edges(tree)\n",
    "    \n",
    "    return G\n",
    "\n",
    "# Example usage\n",
    "newick_str = \"((A,B)M, (D, L)X)F;\"\n",
    "G_1 = newick_to_networkx(newick_str)\n",
    "print(\"Nodes:\", G_1.nodes())\n",
    "print(\"Edges:\", G_1.edges())\n",
    "\n",
    "G_2 = newick_to_networkx(\"((A,B)X, (D, L)M)F;\")\n",
    "print(\"Nodes:\", G_2.nodes())\n",
    "print(\"Edges:\", G_2.edges())\n",
    "\n",
    "def label_based_cost(u, v):\n",
    "    # if u.get(\"label\") and v.get(\"label\"):\n",
    "    #     return 0 if G_1.nodes[u['label']] == G_2.nodes[v['label']] else 1\n",
    "    # return 0\n",
    "    label_u = G_1.nodes[u['label']] if u.get(\"label\") else u\n",
    "    label_v = G_2.nodes[v['label']] if v.get(\"label\") else v\n",
    "    print(u.get(\"label\"), v.get(\"label\"))\n",
    "    return 0 if label_u == label_v else 1\n",
    "\n",
    "\n",
    "nx.graph_edit_distance(G_1, G_2,\n",
    "                             node_subst_cost=label_based_cost,\n",
    "                             node_del_cost=lambda n: 1,\n",
    "                             node_ins_cost=lambda n: 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ┌─A\n",
      "    ┌─M─┤\n",
      "    │   └─B\n",
      "──F─┤\n",
      "    │   ┌─D\n",
      "    └─X─┤\n",
      "        └─L\n",
      "        ┌─A\n",
      "    ┌─X─┤\n",
      "    │   └─B\n",
      "──F─┤\n",
      "    │   ┌─D\n",
      "    └─M─┤\n",
      "        └─L\n",
      "Nodes (G_1): [('F', {'label': 'F'}), ('M', {'label': 'M'}), ('A', {'label': 'A'}), ('B', {'label': 'B'}), ('X', {'label': 'X'}), ('D', {'label': 'D'}), ('L', {'label': 'L'})]\n",
      "Edges (G_1): [('F', 'M'), ('F', 'X'), ('M', 'A'), ('M', 'B'), ('X', 'D'), ('X', 'L')]\n",
      "Nodes (G_2): [('F', {'label': 'F'}), ('X', {'label': 'X'}), ('A', {'label': 'A'}), ('B', {'label': 'B'}), ('M', {'label': 'M'}), ('D', {'label': 'D'}), ('L', {'label': 'L'})]\n",
      "Edges (G_2): [('F', 'X'), ('F', 'M'), ('X', 'A'), ('X', 'B'), ('M', 'D'), ('M', 'L')]\n",
      "Graph Edit Distance (GED): 1.0\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import newick\n",
    "\n",
    "def newick_to_networkx(newick_str):\n",
    "    # Parse the Newick tree\n",
    "    tree = newick.loads(newick_str)[0]  # loads returns a list of trees; we use the first\n",
    "    print(tree.ascii_art())\n",
    "    \n",
    "    # Initialize an empty directed NetworkX graph\n",
    "    G = nx.DiGraph()\n",
    "    unique_id = 0  # Counter for unnamed internal nodes\n",
    "\n",
    "    # Recursive function to add nodes and edges to the graph\n",
    "    def add_edges(node, parent=None):\n",
    "        nonlocal unique_id\n",
    "        current_node = node.name if node.name else f\"Internal_{unique_id}\"\n",
    "        if not node.name:\n",
    "            unique_id += 1\n",
    "\n",
    "        # Add the current node\n",
    "        G.add_node(current_node, label=node.name)  # Internal nodes without names get a unique ID\n",
    "        if parent is not None:\n",
    "            G.add_edge(parent, current_node)\n",
    "\n",
    "        # Recursively add children\n",
    "        for child in node.descendants:\n",
    "            add_edges(child, current_node)\n",
    "\n",
    "    # Start building the graph from the root of the tree\n",
    "    add_edges(tree)\n",
    "    return G\n",
    "\n",
    "# Graphs from Newick strings\n",
    "newick_1 = \"((A,B)M, (D,L)X)F;\"\n",
    "newick_2 = \"((A,B)X, (D,L)M)F;\"\n",
    "\n",
    "G_1 = newick_to_networkx(newick_1)\n",
    "G_2 = newick_to_networkx(newick_2)\n",
    "\n",
    "print(\"Nodes (G_1):\", G_1.nodes(data=True))\n",
    "print(\"Edges (G_1):\", G_1.edges())\n",
    "print(\"Nodes (G_2):\", G_2.nodes(data=True))\n",
    "print(\"Edges (G_2):\", G_2.edges())\n",
    "\n",
    "# Cost functions for GED\n",
    "def label_based_cost(u, v):\n",
    "    # Retrieve labels and compare\n",
    "    label_u = u.get(\"label\", \"\")\n",
    "    label_v = v.get(\"label\", \"\")\n",
    "    return 0 if label_u == label_v else 1/2\n",
    "\n",
    "# Deletion and insertion cost\n",
    "def node_deletion_cost(node):\n",
    "    return 1\n",
    "\n",
    "def node_insertion_cost(node):\n",
    "    return 1\n",
    "\n",
    "# Compute GED\n",
    "ged = nx.graph_edit_distance(\n",
    "    G_1, G_2,\n",
    "    node_subst_cost=label_based_cost,\n",
    "    node_del_cost=node_deletion_cost,\n",
    "    node_ins_cost=node_insertion_cost,\n",
    ")\n",
    "\n",
    "print(\"Graph Edit Distance (GED):\", ged)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G1 = nx.cycle_graph(6)\n",
    "G2 = nx.wheel_graph(7)\n",
    "nx.graph_edit_distance(G1, G2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (0, 5), (1, 2), (2, 3), (3, 4), (4, 5)]\n",
      "[0, 1, 2, 3, 4, 5]\n",
      "[(0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6), (1, 2), (1, 6), (2, 3), (3, 4), (4, 5), (5, 6)]\n",
      "[0, 1, 2, 3, 4, 5, 6]\n"
     ]
    }
   ],
   "source": [
    "print(G1.edges())\n",
    "print(G1.nodes())\n",
    "\n",
    "\n",
    "print(G2.edges())\n",
    "print(G2.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "def constant_cost(u, v):\n",
    "    return 1 if u != v else 0  # Cost is 1 for differing nodes, 0 for identical ones\n",
    "\n",
    "\n",
    "ged = nx.graph_edit_distance(G_1, G_2,\n",
    "                             node_subst_cost=constant_cost,\n",
    "                             node_del_cost=lambda n: 1,\n",
    "                             node_ins_cost=lambda n: 1)\n",
    "\n",
    "print(ged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
